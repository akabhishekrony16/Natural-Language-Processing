{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                       is so sad for my APL frie...\n",
       "1          0                     I missed the New Moon trail...\n",
       "2          1                            omg its already 7:30 :O\n",
       "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop('ItemID',axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  no pavel tonight &lt;Tigersfan &gt;\n",
      "no pavel tonight <Tigersfan >\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "example1 = BeautifulSoup(train.SentimentText[100], 'lxml')\n",
    "print(train.SentimentText[100])\n",
    "print (example1.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove‘@’mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" @georgediaz #Magic ..thinking less than 50 % chance Hedo stays in Orlando. He's gonna go for the $$. They all do. Can't blame him though.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SentimentText[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  #Magic ..thinking less than 50 % chance Hedo stays in Orlando. He's gonna go for the $$. They all do. Can't blame him though.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'@[A-Za-z0-9]+','',train.SentimentText[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URL links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    awhhe man.... I'm completely useless rt now. Funny, all I can do is twitter. http://myloc.me/27HX\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SentimentText[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    awhhe man.... I'm completely useless rt now. Funny, all I can do is twitter. \""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('https?://[A-Za-z0-9./]+','',train.SentimentText[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove hashtag / numbers / punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" #asylm J2 panel is over. Guess it's back to normal life.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SentimentText[132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  asylm J  panel is over  Guess it s back to normal life '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^a-zA-Z]\", \" \", train.SentimentText[132])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foo', 'bar', 'sentence']\n",
      "['foo', 'bar', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "stop = set(stopwords.words('english'))\n",
    "sentence = \"this is a foo bar sentence\"\n",
    "print([i for i in sentence.lower().split() if i not in stop])\n",
    "print([i for i in word_tokenize(sentence.lower()) if i not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat run ran cactu cactus cacti commun commun\n",
      "cat running ran cactus cactus cactus community community\n"
     ]
    }
   ],
   "source": [
    "sent = \"cats running ran cactus cactuses cacti community communities\"\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "port = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "print(\" \".join([port.stem(i) for i in sent.split()]))\n",
    "print(\" \".join([wnl.lemmatize(i) for i in sent.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I fasting in school'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "sent = \"I fastings in schoole\"\n",
    "str(TextBlob(sent).correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(train['SentimentText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(train['SentimentText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193514, 100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.twitter.27B.100d.txt'\n",
    "word2vec_output_file = 'glove.twitter.27B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "filename = 'glove.twitter.27B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.9898e-02,  9.0736e-01,  3.2747e-01,  1.9906e-01, -4.2242e-01,\n",
       "       -1.1457e-01,  1.0035e+00,  3.0591e-01,  7.1547e-02,  4.0001e-01,\n",
       "       -9.6573e-02, -2.1317e-01, -4.3520e+00,  3.3282e-01, -4.0430e-01,\n",
       "       -3.3951e-01,  4.8600e-03,  5.2763e-01, -3.2438e-02,  1.4857e-01,\n",
       "       -3.8666e-01,  5.0101e-02,  6.3554e-02,  6.7353e-02,  1.5601e-01,\n",
       "       -1.9567e-01,  1.1034e-01, -4.4742e-01,  1.7990e-01, -6.2470e-01,\n",
       "       -2.4815e-01,  3.3326e-01, -2.4696e-01,  1.3638e-01, -2.5248e-01,\n",
       "        5.6508e-01,  2.7245e-01, -4.3211e-03,  5.3012e-01,  4.3394e-01,\n",
       "       -1.1828e+00, -2.4079e-01,  7.1431e-01, -1.0715e-03,  2.4606e-01,\n",
       "        3.0575e-01,  1.7527e-01, -7.6920e-01, -1.4829e-01,  7.6699e-01,\n",
       "       -5.2685e-01,  2.5166e-01,  6.1851e-01,  3.2307e-01,  1.7608e-01,\n",
       "       -4.4362e-01,  3.4042e-01,  3.7783e-01,  1.8740e-01,  1.8865e-01,\n",
       "        7.2610e-01,  7.3078e-02,  4.9100e-01, -4.6518e-01,  1.2580e-01,\n",
       "       -1.5894e-01, -3.1325e-01, -9.4356e-02, -2.1148e-01,  1.2932e-01,\n",
       "        5.6518e-01,  4.3678e-01,  3.5361e-01,  2.0354e-01,  2.0340e-01,\n",
       "        1.0977e-01,  1.9595e-01,  1.7445e-01,  3.9514e-01,  4.4946e-01,\n",
       "        2.0205e+00, -2.4376e-01, -4.1825e-01,  4.7127e-02,  6.5048e-01,\n",
       "        3.3388e-02, -5.2080e-01,  8.6132e-02,  4.2310e-01, -8.5000e-02,\n",
       "       -4.2931e-01,  4.0886e-01,  6.8752e-02, -2.3476e-01,  5.5531e-02,\n",
       "        5.2814e-02,  2.0883e-01,  3.6886e-01,  1.7496e-01, -5.8892e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['wait']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
